{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Masking\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "from keras import backend as k\n",
    "from keras import callbacks\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#from six.moves import xrange\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.layers import LSTM,GRU\n",
    "from keras.layers import Lambda\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "\n",
    "from keras.optimizers import RMSprop,adam\n",
    "from keras.callbacks import History\n",
    "\n",
    "#import wtte.weibull as weibull\n",
    "#import wtte.wtte as wtte\n",
    "\n",
    "#from wtte.wtte import WeightWatcher\n",
    "\n",
    "np.random.seed(1337)\n",
    "pd.set_option(\"display.max_rows\",1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weibull_loss_discrete(y_true, y_pred, name=None):\n",
    "    \"\"\"calculates a keras loss op designed for the sequential api.\n",
    "    \n",
    "        Discrete log-likelihood for Weibull hazard function on censored survival data.\n",
    "        For math, see \n",
    "        https://ragulpr.github.io/assets/draft_master_thesis_martinsson_egil_wtte_rnn_2016.pdf (Page 35)\n",
    "        \n",
    "        Args:\n",
    "            y_true: tensor with last dimension having length 2\n",
    "                with y_true[:,...,0] = time to event, \n",
    "                     y_true[:,...,1] = indicator of not censored\n",
    "                \n",
    "            y_pred: tensor with last dimension having length 2 \n",
    "                with y_pred[:,...,0] = alpha, \n",
    "                     y_pred[:,...,1] = beta\n",
    "\n",
    "        Returns:\n",
    "            A positive `Tensor` of same shape as input\n",
    "            \n",
    "    \"\"\"    \n",
    "    y,u = y_true[..., 0], y_true[..., 0]\n",
    "    a,b = y_pred[..., 0], y_pred[..., 1]\n",
    "\n",
    "    hazard0 = K.pow((y + 1e-35) / a, b)\n",
    "    hazard1 = K.pow((y + 1.0) / a, b)\n",
    "    \n",
    "    loglikelihoods = u * K.log(K.exp(hazard1 - hazard0) - 1.0) - hazard1\n",
    "    loss = -1 * K.mean(loglikelihoods)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def output_lambda(x, init_alpha=1.0, max_beta_value=5.0, max_alpha_value=None):\n",
    "    \"\"\"Elementwise (Lambda) computation of alpha and regularized beta.\n",
    "\n",
    "        Alpha: \n",
    "        (activation) \n",
    "        Exponential units seems to give faster training than \n",
    "        the original papers softplus units. Makes sense due to logarithmic\n",
    "        effect of change in alpha. \n",
    "        (initialization) \n",
    "        To get faster training and fewer exploding gradients,\n",
    "        initialize alpha to be around its scale when beta is around 1.0,\n",
    "        approx the expected value/mean of training tte. \n",
    "        Because we're lazy we want the correct scale of output built\n",
    "        into the model so initialize implicitly; \n",
    "        multiply assumed exp(0)=1 by scale factor `init_alpha`.\n",
    "\n",
    "        Beta: \n",
    "        (activation) \n",
    "        We want slow changes when beta-> 0 so Softplus made sense in the original \n",
    "        paper but we get similar effect with sigmoid. It also has nice features.\n",
    "        (regularization) Use max_beta_value to implicitly regularize the model\n",
    "        (initialization) Fixed to begin moving slowly around 1.0\n",
    "\n",
    "        Assumes tensorflow backend.\n",
    "\n",
    "        Args:\n",
    "            x: tensor with last dimension having length 2\n",
    "                with x[...,0] = alpha, x[...,1] = beta\n",
    "\n",
    "        Usage:\n",
    "            model.add(Dense(2))\n",
    "            model.add(Lambda(output_lambda, arguments={\"init_alpha\":100., \"max_beta_value\":2.0}))\n",
    "        Returns:\n",
    "            A positive `Tensor` of same shape as input\n",
    "    \"\"\"\n",
    "    a, b = x[..., 0], x[..., 1]\n",
    "\n",
    "    # Implicitly initialize alpha:\n",
    "    if max_alpha_value is None:\n",
    "        a = init_alpha * K.exp(a)\n",
    "    else:\n",
    "        a = init_alpha * K.clip(x=a, min_value=K.epsilon(),\n",
    "                                max_value=max_alpha_value)\n",
    "\n",
    "    m = max_beta_value\n",
    "    if m > 1.05:  # some value >>1.0\n",
    "        # shift to start around 1.0\n",
    "        # assuming input is around 0.0\n",
    "        _shift = np.log(m - 1.0)\n",
    "\n",
    "        b = K.sigmoid(b - _shift)\n",
    "    else:\n",
    "        b = K.sigmoid(b)\n",
    "\n",
    "    # Clipped sigmoid : has zero gradient at 0,1\n",
    "    # Reduces the small tendency of instability after long training\n",
    "    # by zeroing gradient.\n",
    "    b = m * K.clip(x=b, min_value=K.epsilon(), max_value=1. - K.epsilon())\n",
    "\n",
    "    x = K.stack([a, b], axis=-1)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = 'unit_number'\n",
    "time_col = 'time'\n",
    "feature_cols = [ 'op_setting_1', 'op_setting_2', 'op_setting_3'] + ['sensor_measurement_{}'.format(x) for x in range(1,22)]\n",
    "column_names = [id_col, time_col] + feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True, threshold=10000)\n",
    "\n",
    "train_orig = pd.read_csv('../../keras-wtte-rnn/train.csv', header=None, names=column_names)\n",
    "test_x_orig = pd.read_csv('../../keras-wtte-rnn/test_x.csv', header=None, names=column_names)\n",
    "test_y_orig = pd.read_csv('../../keras-wtte-rnn/test_y.csv', header=None, names=['T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_orig.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_x_orig['TTF'] = test_x_orig.groupby(\"unit_number\")[\"time\"].rank(method=\"min\", ascending=False)\n",
    "mapper = test_y_orig[\"T\"] - 1\n",
    "mapped_value = test_x_orig[\"unit_number\"].map(mapper)\n",
    "test_x_orig['TTF'] = test_x_orig['TTF'] + mapped_value\n",
    "test_x_orig.set_index(['unit_number', 'time'], verify_integrity=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_orig['TTF'] = train_orig.groupby(\"unit_number\")[\"time\"].rank(method=\"min\", ascending=False)\n",
    "train_orig.set_index(['unit_number', 'time'], verify_integrity=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>op_setting_1</th>\n",
       "      <th>op_setting_2</th>\n",
       "      <th>op_setting_3</th>\n",
       "      <th>sensor_measurement_1</th>\n",
       "      <th>sensor_measurement_2</th>\n",
       "      <th>sensor_measurement_3</th>\n",
       "      <th>sensor_measurement_4</th>\n",
       "      <th>sensor_measurement_5</th>\n",
       "      <th>sensor_measurement_6</th>\n",
       "      <th>sensor_measurement_7</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_measurement_13</th>\n",
       "      <th>sensor_measurement_14</th>\n",
       "      <th>sensor_measurement_15</th>\n",
       "      <th>sensor_measurement_16</th>\n",
       "      <th>sensor_measurement_17</th>\n",
       "      <th>sensor_measurement_18</th>\n",
       "      <th>sensor_measurement_19</th>\n",
       "      <th>sensor_measurement_20</th>\n",
       "      <th>sensor_measurement_21</th>\n",
       "      <th>TTF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unit_number</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.36</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.75</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.26</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.45</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  op_setting_1  op_setting_2  op_setting_3  \\\n",
       "unit_number time                                             \n",
       "1           1          -0.0007       -0.0004         100.0   \n",
       "            2           0.0019       -0.0003         100.0   \n",
       "            3          -0.0043        0.0003         100.0   \n",
       "            4           0.0007        0.0000         100.0   \n",
       "            5          -0.0019       -0.0002         100.0   \n",
       "\n",
       "                  sensor_measurement_1  sensor_measurement_2  \\\n",
       "unit_number time                                               \n",
       "1           1                   518.67                641.82   \n",
       "            2                   518.67                642.15   \n",
       "            3                   518.67                642.35   \n",
       "            4                   518.67                642.35   \n",
       "            5                   518.67                642.37   \n",
       "\n",
       "                  sensor_measurement_3  sensor_measurement_4  \\\n",
       "unit_number time                                               \n",
       "1           1                  1589.70               1400.60   \n",
       "            2                  1591.82               1403.14   \n",
       "            3                  1587.99               1404.20   \n",
       "            4                  1582.79               1401.87   \n",
       "            5                  1582.85               1406.22   \n",
       "\n",
       "                  sensor_measurement_5  sensor_measurement_6  \\\n",
       "unit_number time                                               \n",
       "1           1                    14.62                 21.61   \n",
       "            2                    14.62                 21.61   \n",
       "            3                    14.62                 21.61   \n",
       "            4                    14.62                 21.61   \n",
       "            5                    14.62                 21.61   \n",
       "\n",
       "                  sensor_measurement_7  ...  sensor_measurement_13  \\\n",
       "unit_number time                        ...                          \n",
       "1           1                   554.36  ...                2388.02   \n",
       "            2                   553.75  ...                2388.07   \n",
       "            3                   554.26  ...                2388.03   \n",
       "            4                   554.45  ...                2388.08   \n",
       "            5                   554.00  ...                2388.04   \n",
       "\n",
       "                  sensor_measurement_14  sensor_measurement_15  \\\n",
       "unit_number time                                                 \n",
       "1           1                   8138.62                 8.4195   \n",
       "            2                   8131.49                 8.4318   \n",
       "            3                   8133.23                 8.4178   \n",
       "            4                   8133.83                 8.3682   \n",
       "            5                   8133.80                 8.4294   \n",
       "\n",
       "                  sensor_measurement_16  sensor_measurement_17  \\\n",
       "unit_number time                                                 \n",
       "1           1                      0.03                    392   \n",
       "            2                      0.03                    392   \n",
       "            3                      0.03                    390   \n",
       "            4                      0.03                    392   \n",
       "            5                      0.03                    393   \n",
       "\n",
       "                  sensor_measurement_18  sensor_measurement_19  \\\n",
       "unit_number time                                                 \n",
       "1           1                      2388                  100.0   \n",
       "            2                      2388                  100.0   \n",
       "            3                      2388                  100.0   \n",
       "            4                      2388                  100.0   \n",
       "            5                      2388                  100.0   \n",
       "\n",
       "                  sensor_measurement_20  sensor_measurement_21    TTF  \n",
       "unit_number time                                                       \n",
       "1           1                     39.06                23.4190  192.0  \n",
       "            2                     39.00                23.4236  191.0  \n",
       "            3                     38.95                23.3442  190.0  \n",
       "            4                     38.88                23.3739  189.0  \n",
       "            5                     38.90                23.4044  188.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\nlp\\lib\\site-packages\\ipykernel\\zmqshell.py:533: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Combine the X values to normalize them, \n",
    "all_data_orig = pd.concat([train_orig, test_x_orig])\n",
    "# print(all_data_orig.columns, all_data_orig.index)\n",
    "all_data = all_data_orig.copy()\n",
    "# all_data[feature_cols] = normalize(all_data[feature_cols].values)\n",
    "\n",
    "def preprocess(df, feature_cols, scaler=None):\n",
    "    try:\n",
    "        df.loc[:, feature_cols] = scaler.transform(df[feature_cols])\n",
    "    except AttributeError:\n",
    "        df.loc[:, feature_cols] = StandardScaler().fit_transform(df[feature_cols])\n",
    "    \n",
    "    selector = VarianceThreshold() #Defaults to 0.0, e.g. only remove features with the same value in all samples\n",
    "    #Fit the Model and obtain remaining columns\n",
    "    selector.fit(df[feature_cols])\n",
    "    features = selector.get_support(indices = True) #returns an array of integers corresponding to nonremoved features\n",
    "    features = [column for column in df[feature_cols].columns[features]] #Array of all nonremoved features' names\n",
    "\n",
    "    #Format and Return\n",
    "    selector = pd.DataFrame(selector.transform(df[feature_cols]))\n",
    "    selector.columns = features\n",
    "    selector.index = df.index\n",
    "    return features, selector\n",
    "new_features, all_data = preprocess(all_data, feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['op_setting_1', 'op_setting_2', 'op_setting_3', 'sensor_measurement_1',\n",
       "       'sensor_measurement_2', 'sensor_measurement_3', 'sensor_measurement_4',\n",
       "       'sensor_measurement_5', 'sensor_measurement_6', 'sensor_measurement_7',\n",
       "       'sensor_measurement_8', 'sensor_measurement_9', 'sensor_measurement_10',\n",
       "       'sensor_measurement_11', 'sensor_measurement_12',\n",
       "       'sensor_measurement_13', 'sensor_measurement_14',\n",
       "       'sensor_measurement_15', 'sensor_measurement_16',\n",
       "       'sensor_measurement_17', 'sensor_measurement_18',\n",
       "       'sensor_measurement_19', 'sensor_measurement_20',\n",
       "       'sensor_measurement_21', 'TTF'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_orig.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\nlp\\lib\\site-packages\\ipykernel\\ipkernel.py:196: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  res = shell.run_cell(code, store_history=store_history, silent=silent)\n"
     ]
    }
   ],
   "source": [
    "remaining_cols = [col for col in train_orig.columns.tolist() if col in new_features] + [\"TTF\"]\n",
    "all_data_orig.loc[:, new_features] = all_data\n",
    "all_data_orig = all_data_orig[remaining_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>op_setting_1</th>\n",
       "      <th>op_setting_2</th>\n",
       "      <th>sensor_measurement_2</th>\n",
       "      <th>sensor_measurement_3</th>\n",
       "      <th>sensor_measurement_4</th>\n",
       "      <th>sensor_measurement_6</th>\n",
       "      <th>sensor_measurement_7</th>\n",
       "      <th>sensor_measurement_8</th>\n",
       "      <th>sensor_measurement_9</th>\n",
       "      <th>sensor_measurement_11</th>\n",
       "      <th>sensor_measurement_12</th>\n",
       "      <th>sensor_measurement_13</th>\n",
       "      <th>sensor_measurement_14</th>\n",
       "      <th>sensor_measurement_15</th>\n",
       "      <th>sensor_measurement_17</th>\n",
       "      <th>sensor_measurement_20</th>\n",
       "      <th>sensor_measurement_21</th>\n",
       "      <th>TTF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unit_number</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>-0.314711</td>\n",
       "      <td>-1.373690</td>\n",
       "      <td>-1.644975</td>\n",
       "      <td>0.020217</td>\n",
       "      <td>-0.794964</td>\n",
       "      <td>0.155673</td>\n",
       "      <td>1.008357</td>\n",
       "      <td>-0.396802</td>\n",
       "      <td>-0.864091</td>\n",
       "      <td>-0.090766</td>\n",
       "      <td>0.168348</td>\n",
       "      <td>-0.981906</td>\n",
       "      <td>-0.199424</td>\n",
       "      <td>-0.461431</td>\n",
       "      <td>-0.655669</td>\n",
       "      <td>1.254019</td>\n",
       "      <td>1.091572</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.870755</td>\n",
       "      <td>-1.032895</td>\n",
       "      <td>-0.949920</td>\n",
       "      <td>0.383216</td>\n",
       "      <td>-0.493750</td>\n",
       "      <td>0.155673</td>\n",
       "      <td>0.276905</td>\n",
       "      <td>-0.694283</td>\n",
       "      <td>-0.975799</td>\n",
       "      <td>-0.010603</td>\n",
       "      <td>1.062424</td>\n",
       "      <td>-0.242468</td>\n",
       "      <td>-0.634651</td>\n",
       "      <td>-0.113571</td>\n",
       "      <td>-0.655669</td>\n",
       "      <td>0.902637</td>\n",
       "      <td>1.136638</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.956125</td>\n",
       "      <td>1.011877</td>\n",
       "      <td>-0.528674</td>\n",
       "      <td>-0.272579</td>\n",
       "      <td>-0.368046</td>\n",
       "      <td>0.155673</td>\n",
       "      <td>0.888447</td>\n",
       "      <td>-0.099321</td>\n",
       "      <td>-0.508416</td>\n",
       "      <td>-0.892393</td>\n",
       "      <td>1.264312</td>\n",
       "      <td>-0.834018</td>\n",
       "      <td>-0.528438</td>\n",
       "      <td>-0.509509</td>\n",
       "      <td>-2.018065</td>\n",
       "      <td>0.609819</td>\n",
       "      <td>0.358754</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.323617</td>\n",
       "      <td>-0.010509</td>\n",
       "      <td>-0.528674</td>\n",
       "      <td>-1.162954</td>\n",
       "      <td>-0.644357</td>\n",
       "      <td>0.155673</td>\n",
       "      <td>1.116276</td>\n",
       "      <td>0.346901</td>\n",
       "      <td>-0.690733</td>\n",
       "      <td>-1.453533</td>\n",
       "      <td>1.898818</td>\n",
       "      <td>-0.094581</td>\n",
       "      <td>-0.491813</td>\n",
       "      <td>-1.912263</td>\n",
       "      <td>-0.655669</td>\n",
       "      <td>0.199874</td>\n",
       "      <td>0.649726</td>\n",
       "      <td>189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.861849</td>\n",
       "      <td>-0.692099</td>\n",
       "      <td>-0.486549</td>\n",
       "      <td>-1.152680</td>\n",
       "      <td>-0.128498</td>\n",
       "      <td>0.155673</td>\n",
       "      <td>0.576681</td>\n",
       "      <td>-0.396802</td>\n",
       "      <td>-0.391966</td>\n",
       "      <td>-0.852312</td>\n",
       "      <td>0.932638</td>\n",
       "      <td>-0.686131</td>\n",
       "      <td>-0.493645</td>\n",
       "      <td>-0.181446</td>\n",
       "      <td>0.025530</td>\n",
       "      <td>0.317001</td>\n",
       "      <td>0.948535</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  op_setting_1  op_setting_2  sensor_measurement_2  \\\n",
       "unit_number time                                                     \n",
       "1           1        -0.314711     -1.373690             -1.644975   \n",
       "            2         0.870755     -1.032895             -0.949920   \n",
       "            3        -1.956125      1.011877             -0.528674   \n",
       "            4         0.323617     -0.010509             -0.528674   \n",
       "            5        -0.861849     -0.692099             -0.486549   \n",
       "\n",
       "                  sensor_measurement_3  sensor_measurement_4  \\\n",
       "unit_number time                                               \n",
       "1           1                 0.020217             -0.794964   \n",
       "            2                 0.383216             -0.493750   \n",
       "            3                -0.272579             -0.368046   \n",
       "            4                -1.162954             -0.644357   \n",
       "            5                -1.152680             -0.128498   \n",
       "\n",
       "                  sensor_measurement_6  sensor_measurement_7  \\\n",
       "unit_number time                                               \n",
       "1           1                 0.155673              1.008357   \n",
       "            2                 0.155673              0.276905   \n",
       "            3                 0.155673              0.888447   \n",
       "            4                 0.155673              1.116276   \n",
       "            5                 0.155673              0.576681   \n",
       "\n",
       "                  sensor_measurement_8  sensor_measurement_9  \\\n",
       "unit_number time                                               \n",
       "1           1                -0.396802             -0.864091   \n",
       "            2                -0.694283             -0.975799   \n",
       "            3                -0.099321             -0.508416   \n",
       "            4                 0.346901             -0.690733   \n",
       "            5                -0.396802             -0.391966   \n",
       "\n",
       "                  sensor_measurement_11  sensor_measurement_12  \\\n",
       "unit_number time                                                 \n",
       "1           1                 -0.090766               0.168348   \n",
       "            2                 -0.010603               1.062424   \n",
       "            3                 -0.892393               1.264312   \n",
       "            4                 -1.453533               1.898818   \n",
       "            5                 -0.852312               0.932638   \n",
       "\n",
       "                  sensor_measurement_13  sensor_measurement_14  \\\n",
       "unit_number time                                                 \n",
       "1           1                 -0.981906              -0.199424   \n",
       "            2                 -0.242468              -0.634651   \n",
       "            3                 -0.834018              -0.528438   \n",
       "            4                 -0.094581              -0.491813   \n",
       "            5                 -0.686131              -0.493645   \n",
       "\n",
       "                  sensor_measurement_15  sensor_measurement_17  \\\n",
       "unit_number time                                                 \n",
       "1           1                 -0.461431              -0.655669   \n",
       "            2                 -0.113571              -0.655669   \n",
       "            3                 -0.509509              -2.018065   \n",
       "            4                 -1.912263              -0.655669   \n",
       "            5                 -0.181446               0.025530   \n",
       "\n",
       "                  sensor_measurement_20  sensor_measurement_21    TTF  \n",
       "unit_number time                                                       \n",
       "1           1                  1.254019               1.091572  192.0  \n",
       "            2                  0.902637               1.136638  191.0  \n",
       "            3                  0.609819               0.358754  190.0  \n",
       "            4                  0.199874               0.649726  189.0  \n",
       "            5                  0.317001               0.948535  188.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make engine numbers and days zero-indexed, then split them back into train and test data\n",
    "all_data.index.set_levels((all_data.index.levels[0]-1, all_data.index.levels[1]-1), (0,1), inplace=True)\n",
    "train_ = all_data.iloc[0:train_orig.shape[0], :]\n",
    "test_ = all_data.iloc[train_orig.shape[0]:, :]\n",
    "\n",
    "#train.loc[:, 0:2] -= 1\n",
    "#test.loc[:, 0:2] -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>op_setting_1</th>\n",
       "      <th>op_setting_2</th>\n",
       "      <th>sensor_measurement_2</th>\n",
       "      <th>sensor_measurement_3</th>\n",
       "      <th>sensor_measurement_4</th>\n",
       "      <th>sensor_measurement_6</th>\n",
       "      <th>sensor_measurement_7</th>\n",
       "      <th>sensor_measurement_8</th>\n",
       "      <th>sensor_measurement_9</th>\n",
       "      <th>sensor_measurement_11</th>\n",
       "      <th>sensor_measurement_12</th>\n",
       "      <th>sensor_measurement_13</th>\n",
       "      <th>sensor_measurement_14</th>\n",
       "      <th>sensor_measurement_15</th>\n",
       "      <th>sensor_measurement_17</th>\n",
       "      <th>sensor_measurement_20</th>\n",
       "      <th>sensor_measurement_21</th>\n",
       "      <th>TTF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unit_number</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>-0.314711</td>\n",
       "      <td>-1.373690</td>\n",
       "      <td>-1.644975</td>\n",
       "      <td>0.020217</td>\n",
       "      <td>-0.794964</td>\n",
       "      <td>0.155673</td>\n",
       "      <td>1.008357</td>\n",
       "      <td>-0.396802</td>\n",
       "      <td>-0.864091</td>\n",
       "      <td>-0.090766</td>\n",
       "      <td>0.168348</td>\n",
       "      <td>-0.981906</td>\n",
       "      <td>-0.199424</td>\n",
       "      <td>-0.461431</td>\n",
       "      <td>-0.655669</td>\n",
       "      <td>1.254019</td>\n",
       "      <td>1.091572</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.870755</td>\n",
       "      <td>-1.032895</td>\n",
       "      <td>-0.949920</td>\n",
       "      <td>0.383216</td>\n",
       "      <td>-0.493750</td>\n",
       "      <td>0.155673</td>\n",
       "      <td>0.276905</td>\n",
       "      <td>-0.694283</td>\n",
       "      <td>-0.975799</td>\n",
       "      <td>-0.010603</td>\n",
       "      <td>1.062424</td>\n",
       "      <td>-0.242468</td>\n",
       "      <td>-0.634651</td>\n",
       "      <td>-0.113571</td>\n",
       "      <td>-0.655669</td>\n",
       "      <td>0.902637</td>\n",
       "      <td>1.136638</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.956125</td>\n",
       "      <td>1.011877</td>\n",
       "      <td>-0.528674</td>\n",
       "      <td>-0.272579</td>\n",
       "      <td>-0.368046</td>\n",
       "      <td>0.155673</td>\n",
       "      <td>0.888447</td>\n",
       "      <td>-0.099321</td>\n",
       "      <td>-0.508416</td>\n",
       "      <td>-0.892393</td>\n",
       "      <td>1.264312</td>\n",
       "      <td>-0.834018</td>\n",
       "      <td>-0.528438</td>\n",
       "      <td>-0.509509</td>\n",
       "      <td>-2.018065</td>\n",
       "      <td>0.609819</td>\n",
       "      <td>0.358754</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.323617</td>\n",
       "      <td>-0.010509</td>\n",
       "      <td>-0.528674</td>\n",
       "      <td>-1.162954</td>\n",
       "      <td>-0.644357</td>\n",
       "      <td>0.155673</td>\n",
       "      <td>1.116276</td>\n",
       "      <td>0.346901</td>\n",
       "      <td>-0.690733</td>\n",
       "      <td>-1.453533</td>\n",
       "      <td>1.898818</td>\n",
       "      <td>-0.094581</td>\n",
       "      <td>-0.491813</td>\n",
       "      <td>-1.912263</td>\n",
       "      <td>-0.655669</td>\n",
       "      <td>0.199874</td>\n",
       "      <td>0.649726</td>\n",
       "      <td>189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.861849</td>\n",
       "      <td>-0.692099</td>\n",
       "      <td>-0.486549</td>\n",
       "      <td>-1.152680</td>\n",
       "      <td>-0.128498</td>\n",
       "      <td>0.155673</td>\n",
       "      <td>0.576681</td>\n",
       "      <td>-0.396802</td>\n",
       "      <td>-0.391966</td>\n",
       "      <td>-0.852312</td>\n",
       "      <td>0.932638</td>\n",
       "      <td>-0.686131</td>\n",
       "      <td>-0.493645</td>\n",
       "      <td>-0.181446</td>\n",
       "      <td>0.025530</td>\n",
       "      <td>0.317001</td>\n",
       "      <td>0.948535</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  op_setting_1  op_setting_2  sensor_measurement_2  \\\n",
       "unit_number time                                                     \n",
       "0           0        -0.314711     -1.373690             -1.644975   \n",
       "            1         0.870755     -1.032895             -0.949920   \n",
       "            2        -1.956125      1.011877             -0.528674   \n",
       "            3         0.323617     -0.010509             -0.528674   \n",
       "            4        -0.861849     -0.692099             -0.486549   \n",
       "\n",
       "                  sensor_measurement_3  sensor_measurement_4  \\\n",
       "unit_number time                                               \n",
       "0           0                 0.020217             -0.794964   \n",
       "            1                 0.383216             -0.493750   \n",
       "            2                -0.272579             -0.368046   \n",
       "            3                -1.162954             -0.644357   \n",
       "            4                -1.152680             -0.128498   \n",
       "\n",
       "                  sensor_measurement_6  sensor_measurement_7  \\\n",
       "unit_number time                                               \n",
       "0           0                 0.155673              1.008357   \n",
       "            1                 0.155673              0.276905   \n",
       "            2                 0.155673              0.888447   \n",
       "            3                 0.155673              1.116276   \n",
       "            4                 0.155673              0.576681   \n",
       "\n",
       "                  sensor_measurement_8  sensor_measurement_9  \\\n",
       "unit_number time                                               \n",
       "0           0                -0.396802             -0.864091   \n",
       "            1                -0.694283             -0.975799   \n",
       "            2                -0.099321             -0.508416   \n",
       "            3                 0.346901             -0.690733   \n",
       "            4                -0.396802             -0.391966   \n",
       "\n",
       "                  sensor_measurement_11  sensor_measurement_12  \\\n",
       "unit_number time                                                 \n",
       "0           0                 -0.090766               0.168348   \n",
       "            1                 -0.010603               1.062424   \n",
       "            2                 -0.892393               1.264312   \n",
       "            3                 -1.453533               1.898818   \n",
       "            4                 -0.852312               0.932638   \n",
       "\n",
       "                  sensor_measurement_13  sensor_measurement_14  \\\n",
       "unit_number time                                                 \n",
       "0           0                 -0.981906              -0.199424   \n",
       "            1                 -0.242468              -0.634651   \n",
       "            2                 -0.834018              -0.528438   \n",
       "            3                 -0.094581              -0.491813   \n",
       "            4                 -0.686131              -0.493645   \n",
       "\n",
       "                  sensor_measurement_15  sensor_measurement_17  \\\n",
       "unit_number time                                                 \n",
       "0           0                 -0.461431              -0.655669   \n",
       "            1                 -0.113571              -0.655669   \n",
       "            2                 -0.509509              -2.018065   \n",
       "            3                 -1.912263              -0.655669   \n",
       "            4                 -0.181446               0.025530   \n",
       "\n",
       "                  sensor_measurement_20  sensor_measurement_21    TTF  \n",
       "unit_number time                                                       \n",
       "0           0                  1.254019               1.091572  192.0  \n",
       "            1                  0.902637               1.136638  191.0  \n",
       "            2                  0.609819               0.358754  190.0  \n",
       "            3                  0.199874               0.649726  189.0  \n",
       "            4                  0.317001               0.948535  188.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "def create_rnn_input(df, seq_len = 20):\n",
    "    def sequence_generation(df):\n",
    "        for ID in tqdm_notebook(range(np.max(df.index.get_level_values(\"unit_number\").values))):\n",
    "            feat_seq = (df.loc[ID,:].loc[max(0, cycle-(seq_len-1)):cycle, remaining_cols].values \\\n",
    "                        for cycle in df.query('unit_number == {:d}'.format(ID)).index.get_level_values(\"time\"))\n",
    "            yield from feat_seq\n",
    "    gen_seq = sequence_generation(df)\n",
    "    gen_pad = (np.concatenate((np.pad(arr[..., :-1], ((seq_len-arr.shape[0],0),(0,0)), \"constant\", constant_values=-99),\n",
    "                              np.pad(arr[..., -1:], ((seq_len-arr.shape[0],0),(0,0)), \"linear_ramp\", end_values=arr[0, -1]+seq_len-arr.shape[0])),\n",
    "                              axis=1) for arr in gen_seq)\n",
    "    return gen_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\nlp\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe13f9162194cd895333d432d8c8be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_time = 25\n",
    "train_sequences = create_rnn_input(train_, max_time)\n",
    "#train_seq = np.stack(train_sequences, axis=0)\n",
    "train_tensor = np.stack(train_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.shuffle(train_tensor)\n",
    "train_x, train_y = np.split(train_tensor, [-1], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\nlp\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740b696bfde043749508a26ec63beafc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_sequences = create_rnn_input(test_, max_time)\n",
    "test_tensor = np.stack(test_sequences)\n",
    "# np.random.shuffle(test_tensor)\n",
    "test_x, test_y = np.split(test_tensor, [-1], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x (20431, 25, 17) train_y (20431, 25, 2) test_x (12898, 25, 17) test_y (12898, 25, 2)\n"
     ]
    }
   ],
   "source": [
    "# always observed in our case\n",
    "mask_value = -99\n",
    "train_y = np.concatenate((train_y, np.ones(train_y.shape)), axis=2)\n",
    "test_y = np.concatenate((test_y, np.ones(test_y.shape)), axis=2)\n",
    "print('train_x', train_x.shape, 'train_y', train_y.shape, 'test_x', test_x.shape, 'test_y', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon 1e-10\n",
      "init_alpha:  121.38850149835991\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "K.set_epsilon(1e-10)\n",
    "print('epsilon', K.epsilon())\n",
    "\n",
    "tte_mean_train = np.nanmean(train_y[:,:,0])\n",
    "init_alpha = -1.0/np.log(1.0-1.0/(tte_mean_train+1.0) )\n",
    "init_alpha = init_alpha/np.nanmean(train_y[:,:,1]) # use if lots of censoring\n",
    "print('init_alpha: ',init_alpha)\n",
    "\n",
    "history = History()\n",
    "# weightwatcher = WeightWatcher()\n",
    "nanterminator = callbacks.TerminateOnNaN()\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='loss', \n",
    "                                        factor=0.5, \n",
    "                                        patience=4, \n",
    "                                        verbose=1, \n",
    "                                        mode='auto', \n",
    "                                        min_delta=0.01, \n",
    "                                        cooldown=0, \n",
    "                                        min_lr=1e-6)\n",
    "chkpt = keras.callbacks.ModelCheckpoint(\"modelovf-{val_loss:.2f}.h5\", verbose=1, save_best_only=True)\n",
    "stop = keras.callbacks.EarlyStopping(patience=8, verbose=1, min_delta=1e-3)\n",
    "\n",
    "n_features = train_x.shape[-1]\n",
    "\n",
    "# Start building our model\n",
    "model = Sequential()\n",
    "\n",
    "# Mask parts of the lookback period that are all zeros (i.e., unobserved) so they don't skew the model\n",
    "model.add(Masking(mask_value=mask_value, input_shape=train_x.shape[1:]))\n",
    "\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# LSTM is just a common type of RNN. You could also try anything else (e.g., GRU).\n",
    "# model.add(GRU(20, activation='tanh', recurrent_dropout=0.25))\n",
    "model.add(GRU(64, activation='tanh', return_sequences=True,\n",
    "             kernel_regularizer=keras.regularizers.l1(1e-7)))\n",
    "\n",
    "model.add(GRU(48, activation='tanh', return_sequences=True))\n",
    "#model.add(TimeDistributed(Dense(16, activation=\"relu\")))\n",
    "#model.add(keras.layers.Dropout(0.5))\n",
    "# We need 2 neurons to output Alpha and Beta parameters for our Weibull distribution\n",
    "# model.add(TimeDistributed(Dense(2)))\n",
    "# model.add(Dense(10, kernel_regularizer=keras.regularizers.l2(3e-3)))\n",
    "model.add(Lambda(output_lambda, arguments={\"init_alpha\": init_alpha,\n",
    "                                           \"max_beta_value\": 1000}))\n",
    "\n",
    "model.compile(loss=weibull_loss_discrete, optimizer=adam(lr=.01))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_6 (Masking)          (None, 25, 17)            0         \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 (None, 25, 64)            15744     \n",
      "_________________________________________________________________\n",
      "gru_12 (GRU)                 (None, 25, 48)            16272     \n",
      "_________________________________________________________________\n",
      "lambda_6 (Lambda)            (None, 25, 2)             0         \n",
      "=================================================================\n",
      "Total params: 32,016\n",
      "Trainable params: 32,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17877 samples, validate on 2554 samples\n",
      "Epoch 1/100\n",
      " - 31s - loss: 98.7062 - val_loss: 62.9752\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 62.97517, saving model to modelovf-62.98.h5\n",
      "Epoch 2/100\n",
      " - 26s - loss: 86.6435 - val_loss: 62.8398\n",
      "\n",
      "Epoch 00002: val_loss improved from 62.97517 to 62.83976, saving model to modelovf-62.84.h5\n",
      "Epoch 3/100\n",
      " - 24s - loss: 86.5880 - val_loss: 62.8165\n",
      "\n",
      "Epoch 00003: val_loss improved from 62.83976 to 62.81651, saving model to modelovf-62.82.h5\n",
      "Epoch 4/100\n",
      " - 25s - loss: 86.5735 - val_loss: 62.8087\n",
      "\n",
      "Epoch 00004: val_loss improved from 62.81651 to 62.80872, saving model to modelovf-62.81.h5\n",
      "Epoch 5/100\n",
      " - 25s - loss: 86.5678 - val_loss: 62.8052\n",
      "\n",
      "Epoch 00005: val_loss improved from 62.80872 to 62.80516, saving model to modelovf-62.81.h5\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-75325d1a53df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.125\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m           callbacks=[nanterminator, reduce_lr, chkpt, stop])\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\envs\\nlp\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlp\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlp\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlp\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1399\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1400\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fit = model.fit(train_x, train_y,\n",
    "          epochs=100,\n",
    "          batch_size=96, \n",
    "          verbose=2,\n",
    "          validation_split=0.125,\n",
    "          callbacks=[nanterminator, reduce_lr, chkpt, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nanterminator = callbacks.TerminateOnNaN()\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='loss', \n",
    "                                        factor=0.5, \n",
    "                                        patience=4, \n",
    "                                        verbose=1, \n",
    "                                        mode='auto', \n",
    "                                        min_delta=0.01, \n",
    "                                        cooldown=0, \n",
    "                                        min_lr=1e-6)\n",
    "chkpt = keras.callbacks.ModelCheckpoint(\"weights.{epoch:3d}-{val_loss:.2f}.h5\", verbose=1, save_best_only=True)\n",
    "stop = keras.callbacks.EarlyStopping(patience=8, verbose=1, min_delta=1e-3)\n",
    "\n",
    "model.fit(train_x, train_y,\n",
    "              epochs=100,\n",
    "              batch_size=96, \n",
    "              verbose=2,\n",
    "              validation_split=0.12,\n",
    "              callbacks=[nanterminator, reduce_lr, chkpt, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"modelch-4.75.h5\", custom_objects={\"activate\": activate, \"weibull_loglik_discrete\": weibull_loglik_discrete})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-0de5469d2c7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'training'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'validation'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#weightwatcher.plot()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fit' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(fit.history['loss'],    label='training')\n",
    "plt.plot(fit.history['val_loss'],label='validation')\n",
    "plt.title('loss')\n",
    "plt.legend()\n",
    "#weightwatcher.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions and put them alongside the real TTE and event indicator values\n",
    "test_predict = model.predict(test_x)\n",
    "#test_predict = np.resize(test_predict, (100, 2))\n",
    "test_result = np.concatenate((test_y, test_predict), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12898, 25, 4)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_results_df = pd.DataFrame(test_result[:,-1,:], columns=['T', 'E', 'alpha', 'beta'])\n",
    "test_results_df[['unit_number', 'time']] = test_.reset_index(drop=False)[[\"unit_number\", \"time\"]]\n",
    "\n",
    "# test_results_df = pd.concat([test_x_orig, test_results_df], axis=1)\n",
    "# test_results_df = test_results_df.merge(test_x_orig, on=['unit_number'], how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weibull_pdf(alpha, beta, t):\n",
    "    return (beta/alpha) * (t/alpha)**(beta-1)*np.exp(- (t/alpha)**beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weibull_median(alpha, beta):\n",
    "    return alpha*(-np.log(.5))**(1/beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "def weibull_mean(alpha, beta):\n",
    "    return alpha * scipy.special.gamma(1 + 1/beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weibull_mode(alpha, beta):\n",
    "    # assert len(alpha) == len(beta)\n",
    "    assert np.all(beta > 0)\n",
    "    try:\n",
    "        return alpha * ((beta-1)/beta)**(1/beta) if beta > 1 else 0\n",
    "    except ValueError:\n",
    "        x = alpha * ((beta-1)/beta)**(1/beta)\n",
    "        x[beta <= 1] = 0\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weibull_conf(alpha, beta, c):\n",
    "    return alpha * np.power(np.log(1./(1-c)), 1./beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df['T'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "t=np.arange(0,300)\n",
    "alpha = test_results_df['alpha'].mean()\n",
    "beta = test_results_df['beta'].mean()\n",
    "\n",
    "plt.plot(t, weibull_pdf(alpha,beta, t))\n",
    "mu = weibull_mean(alpha, beta)\n",
    "median =weibull_median(alpha, beta)\n",
    "mode = weibull_mode(alpha, beta)\n",
    "plt.axvline(mu, ls='--', label='mean')\n",
    "plt.axvline(median, ls='--', color='red', label='median')\n",
    "plt.axvline(mode, ls='--', color='green', label='mode')\n",
    "n, bins, patches = plt.hist(test_results_df['T'], 20, normed=1, facecolor='grey', alpha=0.75, label='T')\n",
    "plt.legend()\n",
    "\n",
    "plt.gcf().set_size_inches(12.5, 8)\n",
    "plt.title('Average Weibull distribution over test set')\n",
    "print('alpha', alpha, 'beta', beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "t=np.arange(0,300)\n",
    "alpha = train_results_df['alpha'].mean()\n",
    "beta = train_results_df['beta'].mean()\n",
    "\n",
    "plt.plot(t, weibull_pdf(alpha,beta, t))\n",
    "mu = weibull_mean(alpha, beta)\n",
    "median =weibull_median(alpha, beta)\n",
    "mode = weibull_mode(alpha, beta)\n",
    "plt.axvline(mu, ls='--', label='mean')\n",
    "plt.axvline(median, ls='--', color='red', label='median')\n",
    "plt.axvline(mode, ls='--', color='green', label='mode')\n",
    "n, bins, patches = plt.hist(train_results_df['T'], 20, normed=1, facecolor='grey', alpha=0.75, label='T')\n",
    "plt.legend()\n",
    "\n",
    "plt.gcf().set_size_inches(12.5, 8)\n",
    "plt.title('Average Weibull distribution over train set')\n",
    "print('alpha', alpha, 'beta', beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "palette=sns.color_palette(\"RdBu_r\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.palplot(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_orig.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_columns = [x for x in test_x_orig.columns if x not in {'unit_number', 'time'}]\n",
    "\n",
    "mins=train_orig[feature_columns].min()\n",
    "maxs=train_orig[feature_columns].max()\n",
    "\n",
    "for unit_no, grp in test_x_orig.groupby('unit_number'):\n",
    "    df=grp.set_index('time')\n",
    "    df = df[feature_columns]\n",
    "    df=(df - mins)/ (maxs - mins)\n",
    "    df.plot(figsize=(12.5,8))\n",
    "    plt.title(unit_no)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def plot_weibull_predictions(results_df):\n",
    "\n",
    "    fig, axarr = plt.subplots(3, figsize=(20,30))\n",
    "\n",
    "    t=np.arange(0,400)\n",
    "\n",
    "    palette = sns.color_palette(\"RdBu_r\", results_df.shape[0] + 1)\n",
    "    color_dict = dict(enumerate(palette))\n",
    "\n",
    "    for i, row in enumerate(results_df.iterrows()):\n",
    "        alpha=row[1]['alpha']\n",
    "        beta = row[1]['beta']\n",
    "        T = row[1]['T']\n",
    "        label = 'a={} b={}'.format(alpha, beta)\n",
    "\n",
    "        color = color_dict[i]\n",
    "        ax= axarr[0]\n",
    "        mode = weibull_mode(alpha, beta)    \n",
    "        y_max = weibull_pdf(alpha, beta, mode)    \n",
    "\n",
    "        ax.plot(t, weibull_pdf(alpha, beta, t), color=color, label=label)\n",
    "        ax.scatter(T, weibull_pdf(alpha,beta, T), color=color, s=100)\n",
    "        ax.vlines(mode, ymin=0, ymax=y_max, colors=color, linestyles='--')\n",
    "\n",
    "        ax.set_title('Weibull distributions')\n",
    "    \n",
    "    ax=axarr[1]\n",
    "    \n",
    "    median_predictions = weibull_median(results_df['alpha'], results_df['beta'])\n",
    "    mean_predictions = results_df[['alpha', 'beta']].apply(lambda row: weibull_mean(row[0], row[1]), axis=1)\n",
    "    mode_predictions = weibull_mode(results_df['alpha'], results_df['beta'])\n",
    "#     x = results_df['time']\n",
    "    \n",
    "#     ax.scatter(x, results_df['T'], label='survival_time', color='black')\n",
    "\n",
    "#     ax.scatter(results_df['T'], median_predictions, label='median_prediction')\n",
    "#     ax.scatter(results_df['T'], mean_predictions, label='mean_prediction')\n",
    "    ax.scatter(results_df['T'], mode_predictions, label='m_prediction')\n",
    "    ax.set_title('MAP prediction Vs. true')\n",
    "    \n",
    "\n",
    "    ax.legend()\n",
    "    \n",
    "    ax=axarr[2]\n",
    "    sns.distplot(results_df['T'] - mode_predictions, ax=ax)\n",
    "    ax.set_title('Error')\n",
    "\n",
    "#     ax.plot(x, results_df['alpha'], label='alpha')\n",
    "#     ax.legend()\n",
    "    \n",
    "#     ax = axarr[3]\n",
    "#     ax.plot(x, results_df['beta'], label='beta')\n",
    "#     ax.legend()\n",
    "    \n",
    "#     ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "#     fig.suptitle(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_weibull_predictions(results_df=test_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df['predicted_mu'] = test_results_df[['alpha', 'beta']].apply(lambda row: weibull_mean(row[0], row[1]), axis=1)\n",
    "test_results_df['predicted_median'] = test_results_df[['alpha', 'beta']].apply(lambda row: weibull_median(row[0], row[1]), axis=1)\n",
    "test_results_df['predicted_mode'] = test_results_df[['alpha', 'beta']].apply(lambda row: weibull_mode(row[0], row[1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(data=test_results_df, y='T', x='predicted_mode',kind=\"reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.jointplot(data=test_results_df, y='T', x='predicted_median',kind=\"kde\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df['error'] = test_results_df['T']-test_results_df['predicted_median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df['error'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(test_results_df['error'], bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict=model.predict(train_x)\n",
    "# train_predict = np.resize(train_predict, (20631, 2))\n",
    "# train_result = np.concatenate((train_y, train_predict), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict.shape\n",
    "train_result = np.concatenate((train_y, train_predict), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results_df = pd.DataFrame(train_result, columns=['T', 'E', 'alpha', 'beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_results_df[['unit_number', 'time']] = train_.reset_index(drop=False)[['unit_number', 'time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results_df['unit_number'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_results_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for unit_number, grp in train_results_df.groupby('unit_number'):\n",
    "    plot_weibull_predictions(grp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results_df.beta.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results_df['predicted_mu'] = train_results_df[['alpha', 'beta']].apply(lambda row: weibull_mean(row[0], row[1]), axis=1)\n",
    "train_results_df['predicted_median'] = train_results_df[['alpha', 'beta']].apply(lambda row: weibull_median(row[0], row[1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "jp = sns.jointplot(data=train_results_df, y='T', x='predicted_median',kind=\"reg\")\n",
    "jp.set_axis_labels(\"Predicted median TTF\", \"True TTF\", fontsize=12)\n",
    "jp.ax_joint.set_title(\"Predicted vs. true time to failure\", y=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "h = sns.jointplot(data=train_results_df, y='T', x='predicted_median',kind=\"kde\" )\n",
    "h.set_axis_labels(\"Predicted median TTF\", \"True TTF\", fontsize=12)\n",
    "h.ax_joint.set_title(\"Kernel density estimate of Predicted vs. true TTF\", y=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results_df['error'] = train_results_df['T']-train_results_df['predicted_median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results_df['error'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(train_results_df['error'], bins=25)\n",
    "plt.xlabel(\"Prediction median error\")\n",
    "plt.ylabel(\"Fraction of total\")\n",
    "plt.title(\"Distribution of errors of predicted median TTF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df[\"02_CI\"] = test_results_df[[\"alpha\", \"beta\"]].apply(lambda cols: weibull_conf(cols[0], cols[1], 0.2), axis=1)\n",
    "test_results_df[\"08_CI\"] = test_results_df[[\"alpha\", \"beta\"]].apply(lambda cols: weibull_conf(cols[0], cols[1], 0.8), axis=1)\n",
    "test_results_df[\"095_CI\"] = test_results_df[[\"alpha\", \"beta\"]].apply(lambda cols: weibull_conf(cols[0], cols[1], 0.95), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(test_results_df.unit_number.max()):\n",
    "    fig, ax = plt.subplots()\n",
    "    sub_df = test_results_df[test_results_df.unit_number == n]\n",
    "    ax.set_xlim(sub_df[\"T\"].max(), sub_df[\"T\"].min())\n",
    "    ax.plot(sub_df[\"T\"], sub_df[\"T\"])\n",
    "    l = ax.plot(sub_df[\"T\"], sub_df[\"predicted_mu\"])\n",
    "    ax.fill_between(sub_df[\"T\"], sub_df[\"02_CI\"], sub_df[\"08_CI\"], alpha = 0.25, color = l[-1].get_color())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = test_results_df[[\"unit_number\", \"time\", \"predicted_median\", \"08_CI\", \"095_CI\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cycles = pd.Series(np.random.randint(50, 34000, 100))\n",
    "map_val = dummy_df[\"unit_number\"].map(dummy_cycles)\n",
    "dummy_df.loc[:, \"flight_cycles\"] = map_val - dummy_df.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df[\"flight\"] = np.random.randint(10, 9999, dummy_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df.loc[:, \"subtype\"] = np.random.choice([\"A319\", \"A320\", \"A321\"], dummy_df.shape[0], True, np.array((0.3,0.63, 0.07)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = dummy_df.loc[dummy_df.groupby(\"unit_number\")[\"time\"].tail(10).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df.insert(dummy_df.shape[1], \"IATA_origin\", \"\")\n",
    "dummy_df.insert(dummy_df.shape[1], \"IATA_destination\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_out = dummy_df[[\"unit_number\", \"flight\", \"flight_cycles\",\n",
    "                      \"predicted_median\", \"08_CI\", \"095_CI\", \n",
    "                      \"subtype\"]].rename(columns={\"unit_number\": \"msn\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_out.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_out.to_excel(\"sample.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
